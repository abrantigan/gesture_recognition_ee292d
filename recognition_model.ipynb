{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EE292D-Letture-Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWUpaBYPSHo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJIQ8qxGtOKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## note: code is largely based on: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/magic_wand/train/train.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV6w3XTCYKsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################  TODO: DATA LOADING  ####################\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-7T-GN4XRMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gest = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z', \\\n",
        "        'period', 'comma', 'exclamation_point', 'apostrophe', 'space', 'backspace', 'done', 'slash', 'quotes', 'unknown']\n",
        "NUM_GESTURES = len(gest)\n",
        "\n",
        "####################  BUILD MODEL  ####################\n",
        "def build_cnn(seq_length):\n",
        "  \"\"\"Builds a convolutional neural network in Keras.\"\"\"\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(\n",
        "          8, (4, 3),\n",
        "          padding=\"same\",\n",
        "          activation=\"relu\",\n",
        "          input_shape=(seq_length, 3, 1)),  # output_shape=(batch, 128, 3, 8)\n",
        "      tf.keras.layers.MaxPool2D((3, 3)),  # (batch, 42, 1, 8)\n",
        "      tf.keras.layers.Dropout(0.1),  # (batch, 42, 1, 8)\n",
        "      tf.keras.layers.Conv2D(16, (4, 1), padding=\"same\",\n",
        "                             activation=\"relu\"),  # (batch, 42, 1, 16)\n",
        "      tf.keras.layers.MaxPool2D((3, 1), padding=\"same\"),  # (batch, 14, 1, 16)\n",
        "      tf.keras.layers.Dropout(0.1),  # (batch, 14, 1, 16)\n",
        "      tf.keras.layers.Flatten(),  # (batch, 224)\n",
        "      tf.keras.layers.Dense(16, activation=\"relu\"),  # (batch, 16)\n",
        "      tf.keras.layers.Dropout(0.1),  # (batch, 16)\n",
        "      tf.keras.layers.Dense(NUM_GESTURES, activation=\"softmax\")  # (batch, NUM_GESTURES)\n",
        "  ])\n",
        "\n",
        "  model_path = os.path.join(\"./netmodels\", \"CNN\")\n",
        "  print(\"Built CNN.\")\n",
        "  # if not os.path.exists(model_path):\n",
        "  #   os.makedirs(model_path)\n",
        "  # model.load_weights(\"./netmodels/CNN/weights.h5\")\n",
        "  return model, model_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmkpj-AFdNer",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee80e432-629d-4264-9d54-47388ac2566e"
      },
      "source": [
        "### Test build CNN function \n",
        "SEQ_LENGTH = 300\n",
        "\n",
        "def test_build_net():\n",
        "    cnn, cnn_path = build_cnn(SEQ_LENGTH)\n",
        "    cnn_data = np.random.rand(60, SEQ_LENGTH, 3, 1)\n",
        "    cnn_prob = cnn(tf.constant(cnn_data, dtype=\"float32\")).numpy()\n",
        "    assert cnn_prob.shape == (60, NUM_GESTURES)\n",
        "    assert cnn_path == \"./netmodels/CNN\"\n",
        "    assert isinstance(cnn, tf.keras.Sequential)\n",
        "\n",
        "test_build_net()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Built CNN.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH8cUVCBaZYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################  UTIL FUNCTIONS ####################\n",
        "\n",
        "def reshape_function(data, label):\n",
        "  reshaped_data = tf.reshape(data, [-1, 3, 1])\n",
        "  return reshaped_data, label\n",
        "\n",
        "\n",
        "def calculate_model_size(model):\n",
        "  print(model.summary())\n",
        "  var_sizes = [\n",
        "      np.product(list(map(int, v.shape))) * v.dtype.size\n",
        "      for v in model.trainable_variables\n",
        "  ]\n",
        "  print(\"Model size:\", sum(var_sizes) / 1024, \"KB\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSJse4YeZKmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################  MODEL TRAINING ####################\n",
        "\n",
        "def train_net(model,\n",
        "model_path,  # pylint: disable=unused-argument\n",
        "    train_len,  # pylint: disable=unused-argument\n",
        "    train_data,\n",
        "    valid_len,\n",
        "    valid_data,  # pylint: disable=unused-argument\n",
        "    test_len,\n",
        "    test_data,\n",
        "    kind):\n",
        "  \"\"\"Trains the model.\"\"\"\n",
        "  calculate_model_size(model)\n",
        "  epochs = 50\n",
        "  batch_size = 64\n",
        "  model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",  metrics=[\"accuracy\"])\n",
        "\n",
        "  ############# Prepare data #############\n",
        "  # TODO: do we need this reshape\n",
        "  train_data = train_data.map(reshape_function)\n",
        "  test_data = test_data.map(reshape_function)\n",
        "  valid_data = valid_data.map(reshape_function)\n",
        "\n",
        "  test_labels = np.zeros(test_len)\n",
        "  idx = 0\n",
        "  for data, label in test_data:  # pylint: disable=unused-variable\n",
        "    test_labels[idx] = label.numpy()\n",
        "    idx += 1\n",
        "  train_data = train_data.batch(batch_size).repeat()\n",
        "  valid_data = valid_data.batch(batch_size)\n",
        "  test_data = test_data.batch(batch_size)\n",
        "\n",
        "  ############## Train model! ##############\n",
        "  model.fit(train_data, epochs=epochs, validation_data=valid_data, steps_per_epoch=1000, \\\n",
        "            validation_steps=int((valid_len - 1) / batch_size + 1), callbacks=[tensorboard_callback])\n",
        "  loss, acc = model.evaluate(test_data)\n",
        "  pred = np.argmax(model.predict(test_data), axis=1)\n",
        "  confusion = tf.math.confusion_matrix(\n",
        "      labels=tf.constant(test_labels),\n",
        "      predictions=tf.constant(pred),\n",
        "      num_classes=NUM_GESTURES)\n",
        "  print(confusion)\n",
        "  print(\"Loss {}, Accuracy {}\".format(loss, acc))\n",
        "\n",
        "  ############## Convert model to TFLite! ##############\n",
        "  # Convert the model to the TensorFlow Lite format without quantization\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "  tflite_model = converter.convert()\n",
        "\n",
        "  # Save the model to disk\n",
        "  open(\"model.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "  # Convert the model to the TensorFlow Lite format with quantization\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "  converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "  tflite_model = converter.convert()\n",
        "\n",
        "  # Save the model to disk\n",
        "  open(\"model_quantized.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "  basic_model_size = os.path.getsize(\"model.tflite\")\n",
        "  print(\"Basic model is %d bytes\" % basic_model_size)\n",
        "  quantized_model_size = os.path.getsize(\"model_quantized.tflite\")\n",
        "  print(\"Quantized model is %d bytes\" % quantized_model_size)\n",
        "  difference = basic_model_size - quantized_model_size\n",
        "  print(\"Difference is %d bytes\" % difference)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX5dq_u8aPBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logdir = \"logs/scalars/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "######################## RUN TRAINING ########################\n",
        "if __name__ == \"__main__\":\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument(\"--model\", \"-m\")\n",
        "  parser.add_argument(\"--person\", \"-p\")\n",
        "  args = parser.parse_args()\n",
        "\n",
        "  seq_length = 128\n",
        "\n",
        "  print(\"Start to load data...\")\n",
        "  if args.person == \"true\":\n",
        "    train_len, train_data, valid_len, valid_data, test_len, test_data = \\\n",
        "        load_data(\"./person_split/train\", \"./person_split/valid\",\n",
        "                  \"./person_split/test\", seq_length)\n",
        "  else:\n",
        "    train_len, train_data, valid_len, valid_data, test_len, test_data = \\\n",
        "        load_data(\"./data/train\", \"./data/valid\", \"./data/test\", seq_length)\n",
        "\n",
        "  print(\"Start to build net...\")\n",
        "  model, model_path = build_cnn(seq_length)\n",
        "\n",
        "  print(\"Start training...\")\n",
        "  train_net(model, model_path, train_len, train_data, valid_len, valid_data,\n",
        "            test_len, test_data, args.model)\n",
        "\n",
        "  print(\"Training finished!\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}