{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######          #add all gestures to gest list!!!!!         #########\n",
    "gest = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "names=[\"lauren\",\"katherine\",\"annie\",\"hallie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../Data/A_lauren_17.csv', '../Data/A_lauren_16.csv', '../Data/A_lauren_24.csv', '../Data/B_lauren_23.csv', '../Data/B_lauren_25.csv', '../Data/B_lauren_2.csv', '../Data/C_lauren_2.csv', '../Data/C_lauren_18.csv', '../Data/C_lauren_23.csv', '../Data/D_lauren_24.csv', '../Data/D_lauren_11.csv', '../Data/D_lauren_4.csv', '../Data/E_lauren_24.csv', '../Data/E_lauren_16.csv', '../Data/E_lauren_5.csv', '../Data/F_lauren_15.csv', '../Data/F_lauren_4.csv', '../Data/F_lauren_21.csv', '../Data/G_lauren_10.csv', '../Data/G_lauren_6.csv', '../Data/G_lauren_25.csv', '../Data/H_lauren_13.csv', '../Data/H_lauren_15.csv', '../Data/H_lauren_6.csv', '../Data/I_lauren_16.csv', '../Data/I_lauren_29.csv', '../Data/I_lauren_12.csv', '../Data/J_lauren_16.csv', '../Data/J_lauren_5.csv', '../Data/J_lauren_18.csv', '../Data/K_lauren_14.csv', '../Data/K_lauren_10.csv', '../Data/K_lauren_30.csv', '../Data/L_lauren_26.csv', '../Data/L_lauren_14.csv', '../Data/L_lauren_2.csv', '../Data/M_lauren_12.csv', '../Data/M_lauren_22.csv', '../Data/M_lauren_14.csv', '../Data/N_lauren_23.csv', '../Data/N_lauren_29.csv', '../Data/N_lauren_20.csv', '../Data/O_lauren_27.csv', '../Data/O_lauren_4.csv', '../Data/O_lauren_8.csv', '../Data/P_lauren_28.csv', '../Data/P_lauren_30.csv', '../Data/P_lauren_8.csv', '../Data/Q_lauren_10.csv', '../Data/Q_lauren_9.csv', '../Data/Q_lauren_18.csv', '../Data/R_lauren_24.csv', '../Data/R_lauren_29.csv', '../Data/R_lauren_5.csv', '../Data/S_lauren_26.csv', '../Data/S_lauren_7.csv', '../Data/S_lauren_2.csv', '../Data/T_lauren_22.csv', '../Data/T_lauren_26.csv', '../Data/T_lauren_6.csv', '../Data/U_lauren_10.csv', '../Data/U_lauren_30.csv', '../Data/U_lauren_14.csv', '../Data/V_lauren_15.csv', '../Data/V_lauren_10.csv', '../Data/V_lauren_4.csv', '../Data/W_lauren_10.csv', '../Data/W_lauren_15.csv', '../Data/W_lauren_1.csv', '../Data/X_lauren_22.csv', '../Data/X_lauren_23.csv', '../Data/X_lauren_30.csv', '../Data/Y_lauren_11.csv', '../Data/Y_lauren_24.csv', '../Data/Y_lauren_9.csv', '../Data/Z_lauren_24.csv', '../Data/Z_lauren_2.csv', '../Data/Z_lauren_13.csv']\n",
      "['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'D', 'D', 'D', 'E', 'E', 'E', 'F', 'F', 'F', 'G', 'G', 'G', 'H', 'H', 'H', 'I', 'I', 'I', 'J', 'J', 'J', 'K', 'K', 'K', 'L', 'L', 'L', 'M', 'M', 'M', 'N', 'N', 'N', 'O', 'O', 'O', 'P', 'P', 'P', 'Q', 'Q', 'Q', 'R', 'R', 'R', 'S', 'S', 'S', 'T', 'T', 'T', 'U', 'U', 'U', 'V', 'V', 'V', 'W', 'W', 'W', 'X', 'X', 'X', 'Y', 'Y', 'Y', 'Z', 'Z', 'Z']\n"
     ]
    }
   ],
   "source": [
    "#train-dev-test 80-10-10\n",
    "#create 3 txt files\n",
    "path = r'../Data/' # Todo: update 'Data' to the name of the folder your data is in\n",
    "os.chdir(path)\n",
    "\n",
    "train=[]\n",
    "dev=[]\n",
    "test=[]\n",
    "\n",
    "train_labels=[]\n",
    "dev_labels=[]\n",
    "test_labels=[]\n",
    "\n",
    "NUM_LETTERS_IN_USE = len(gest)\n",
    "NUM_NAMES_IN_USE = 1 # Todo: increase this as more user data is available\n",
    "\n",
    "##for each letter\n",
    "for g in range(NUM_LETTERS_IN_USE):\n",
    "    allFiles=[]\n",
    "\n",
    "    for file in glob.glob(path + gest[g] + '_' + '*.csv'):  ###if we have folders, just replace this line with the folder path  \n",
    "        allFiles.append(file)\n",
    "\n",
    "    #for names\n",
    "    for n in range(NUM_NAMES_IN_USE):#range(len(names)):\n",
    "        person = [i for i in allFiles if names[n] in i]\n",
    "        random.shuffle(person) #shuffles and stores in lauren\n",
    "        brk1 = round(.8*len(person))\n",
    "        brk2 = brk1 + round(.1*len(person))\n",
    "        \n",
    "        #put 80% of each letter of each person into train folder, and shuffle\n",
    "        train.extend(person[0:brk1])\n",
    "        train_labels.extend([g]*brk1)\n",
    "\n",
    "        #put 10% of each letter of each person into dev folder, and shuffle\n",
    "        dev.extend(person[brk1:brk2])\n",
    "        dev_labels.extend([g]*(brk2-brk1))\n",
    "        \n",
    "        #put 10% of each letter of each person into test folder, and shuffle\n",
    "        test.extend(person[brk2:len(person)])\n",
    "        test_labels.extend([gest[g]]*(len(person)-brk2))\n",
    "    \n",
    "# confirm shapes match\n",
    "assert len(test) == len(test_labels)\n",
    "assert len(train) == len(train_labels)\n",
    "assert len(dev) == len(dev_labels)\n",
    "\n",
    "# print(train)        \n",
    "# print(dev)\n",
    "print(test)\n",
    "print(test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "###flatten lists### # not needed if you use extend\n",
    "# tr = [item for sublist in train for item in sublist]\n",
    "# d = [item for sublist in dev for item in sublist]\n",
    "# ts = [item for sublist in test for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.txt', 'w') as f:\n",
    "    for item in tr:\n",
    "        f.write('%s\\n' % item)\n",
    "with open('dev.txt', 'w') as f:\n",
    "    for item in d:\n",
    "        f.write('%s\\n' % item)\n",
    "with open('test.txt', 'w') as f:\n",
    "    for item in ts:\n",
    "        f.write('%s\\n' % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326.49038461538464\n",
      "308.5\n",
      "788.0\n"
     ]
    }
   ],
   "source": [
    "# Convert data in csv file to list of np arrays, each array one recording\n",
    "# Only keep data where button is being pressed \n",
    "# (note this may have to be altered to extend recordings < 300 samples in length,\n",
    "# this version is just a starting point)\n",
    "def csv_to_nparray(data_list_name):\n",
    "    samples = []\n",
    "    shapes = np.zeros((len(data_list_name),))\n",
    "    for ind, sample in enumerate(data_list_name):\n",
    "        sample_np = np.genfromtxt(sample, delimiter=',')\n",
    "        sample_press_inds = np.argwhere(sample_np[:,0]==1)\n",
    "        samples.append(sample_np[sample_press_inds,:].squeeze())\n",
    "        shapes[ind] = sample_np[sample_press_inds,:].squeeze().shape[0]\n",
    "    return samples, shapes\n",
    "\n",
    "\n",
    "samples, shapes = test_data(train)\n",
    "\n",
    "# Get an idea of how long recordings are! Seems like 300 samples is a good window size\n",
    "print(shapes.mean())\n",
    "print(np.median(shapes))\n",
    "print(shapes.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
